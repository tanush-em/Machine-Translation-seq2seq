{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Imports and Dependancies\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Input\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ],
      "metadata": {
        "id": "8p1tsZWsSrE8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Import\n",
        "data_path = '/content/data.txt'\n",
        "data = pd.read_csv(data_path, sep='\\t', names=['eng', 'spa'])\n",
        "data.sample\n",
        "data['eng'] = data['eng'].apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x.lower()))\n",
        "data['spa'] = data['spa'].apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x.lower()))\n",
        "data['spa'] = data['spa'].apply(lambda x: f\"START_ {x} _END\")"
      ],
      "metadata": {
        "id": "93-XfuM8SwSR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create vocabularies for English and Spanish\n",
        "eng_vocab = set(word for sentence in data['eng'] for word in sentence.split())\n",
        "spa_vocab = set(word for sentence in data['spa'] for word in sentence.split())\n",
        "\n",
        "ing_word2idx = {word: idx + 1 for idx, word in enumerate(sorted(eng_vocab))}\n",
        "spa_word2idx = {word: idx + 1 for idx, word in enumerate(sorted(spa_vocab))}\n",
        "\n",
        "eng_idx2word = {idx: word for word, idx in ing_word2idx.items()}\n",
        "spa_idx2word = {idx: word for word, idx in spa_word2idx.items()}"
      ],
      "metadata": {
        "id": "0XfFm8rJaXjj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine max sequence lengths\n",
        "max_eng_seq_len = max(len(sentence.split()) for sentence in data['eng'])\n",
        "max_spa_seq_len = max(len(sentence.split()) for sentence in data['spa'])\n",
        "\n",
        "# Split data into training and testing sets\n",
        "data_shuffled = shuffle(data, random_state=42)\n",
        "x_train, x_test, y_train, y_test = train_test_split(data_shuffled['eng'], data_shuffled['spa'], test_size=0.15)\n",
        "\n",
        "# Vocabulary sizes\n",
        "num_encoder_tokens = len(ing_word2idx)\n",
        "num_decoder_tokens = len(spa_word2idx) + 1"
      ],
      "metadata": {
        "id": "B13CNcQkdImY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch generator\n",
        "def batch_generator(X, Y, batch_size=128):\n",
        "    while True:\n",
        "        for start in range(0, len(X), batch_size):\n",
        "            end = start + batch_size\n",
        "            X_batch = X[start:end]\n",
        "            Y_batch = Y[start:end]\n",
        "\n",
        "            enc_input = np.zeros((len(X_batch), max_eng_seq_len), dtype=\"float32\")\n",
        "            dec_input = np.zeros((len(Y_batch), max_spa_seq_len), dtype=\"float32\")\n",
        "            dec_output = np.zeros((len(Y_batch), max_spa_seq_len, num_decoder_tokens), dtype=\"float32\")\n",
        "\n",
        "            for i, (eng_sent, spa_sent) in enumerate(zip(X_batch, Y_batch)):\n",
        "                for t, word in enumerate(eng_sent.split()):\n",
        "                    enc_input[i, t] = ing_word2idx.get(word, 0)\n",
        "                for t, word in enumerate(spa_sent.split()):\n",
        "                    if t < len(spa_sent.split()) - 1:\n",
        "                        dec_input[i, t] = spa_word2idx.get(word, 0)\n",
        "                    if t > 0:\n",
        "                        dec_output[i, t - 1, spa_word2idx.get(word, 0)] = 1\n",
        "\n",
        "            yield [enc_input, dec_input], dec_output\n"
      ],
      "metadata": {
        "id": "_x8TFiGndPhw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL ARCHITECTURE\n",
        "# Define the model\n",
        "latent_dim = 256\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "encoder_embedding = Embedding(input_dim=num_encoder_tokens + 1, output_dim=latent_dim, mask_zero=True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "_, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_embedding = Embedding(input_dim=num_decoder_tokens + 1, output_dim=latent_dim, mask_zero=True)(decoder_inputs)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "metadata": {
        "id": "-9sMi_63dSuZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nmt_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "nmt_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "model_checkpoint = ModelCheckpoint(filepath='models/best_nmt_model.keras', monitor='val_loss', save_best_only=True, verbose=1)  # Changed .h5 to .keras\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1, min_delta=1e-4)\n",
        "\n",
        "# Train the model\n",
        "batch_size = 128\n",
        "train_steps = len(x_train) // batch_size\n",
        "val_steps = len(x_test) // batch_size"
      ],
      "metadata": {
        "id": "Wle1guz-dXpu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = nmt_model.fit(\n",
        "    tf.data.Dataset.from_generator(\n",
        "        lambda: batch_generator(x_train, y_train, batch_size),\n",
        "        output_signature=(\n",
        "            (tf.TensorSpec(shape=(None, max_eng_seq_len), dtype=tf.float32),\n",
        "             tf.TensorSpec(shape=(None, max_spa_seq_len), dtype=tf.float32)),\n",
        "            tf.TensorSpec(shape=(None, max_spa_seq_len, num_decoder_tokens), dtype=tf.float32)\n",
        "        )\n",
        "    ),\n",
        "    steps_per_epoch=train_steps,\n",
        "    epochs=50,\n",
        "    validation_data=tf.data.Dataset.from_generator(\n",
        "        lambda: batch_generator(x_test, y_test, batch_size),\n",
        "        output_signature=(\n",
        "            (tf.TensorSpec(shape=(None, max_eng_seq_len), dtype=tf.float32),\n",
        "             tf.TensorSpec(shape=(None, max_spa_seq_len), dtype=tf.float32)),\n",
        "            tf.TensorSpec(shape=(None, max_spa_seq_len, num_decoder_tokens), dtype=tf.float32)\n",
        "        )\n",
        "    ),\n",
        "    validation_steps=val_steps,\n",
        "    callbacks=[model_checkpoint, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Save final weights\n",
        "nmt_model.save_weights('models/final_nmt_weights.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JoK2KwpzdZ9U",
        "outputId": "281b0d59-9dbc-4439-8c65-bca86f2c13a3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was ((tf.float32, tf.float32), tf.float32), but the yielded element was ([array([[9.5120e+03, 9.2950e+03, 1.0000e+00, ..., 0.0000e+00, 0.0000e+00,\n        0.0000e+00],\n       [1.1456e+04, 1.5688e+04, 8.0160e+03, ..., 0.0000e+00, 0.0000e+00,\n        0.0000e+00],\n       [1.5506e+04, 1.8171e+04, 6.2740e+03, ..., 0.0000e+00, 0.0000e+00,\n        0.0000e+00],\n       ...,\n       [1.9070e+03, 1.8172e+04, 1.5506e+04, ..., 0.0000e+00, 0.0000e+00,\n        0.0000e+00],\n       [9.3730e+03, 9.1500e+03, 2.1803e+04, ..., 0.0000e+00, 0.0000e+00,\n        0.0000e+00],\n       [1.3134e+04, 9.1500e+03, 2.2358e+04, ..., 0.0000e+00, 0.0000e+00,\n        0.0000e+00]], dtype=float32), array([[  1., 270., 236., ...,   0.,   0.,   0.],\n       [  1., 270., 236., ...,   0.,   0.,   0.],\n       [  1., 270., 236., ...,   0.,   0.,   0.],\n       ...,\n       [  1., 270., 236., ...,   0.,   0.,   0.],\n       [  1., 270., 236., ...,   0.,   0.,   0.],\n       [  1., 270., 236., ...,   0.,   0.,   0.]], dtype=float32)], array([[[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       ...,\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)).\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 204, in generator_py_func\n    flattened_values = nest.flatten_up_to(output_types, values)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/util/nest.py\", line 237, in flatten_up_to\n    return nest_util.flatten_up_to(\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\", line 1541, in flatten_up_to\n    return _tf_data_flatten_up_to(shallow_tree, input_tree)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\", line 1570, in _tf_data_flatten_up_to\n    _tf_data_assert_shallow_structure(shallow_tree, input_tree)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\", line 1444, in _tf_data_assert_shallow_structure\n    _tf_data_assert_shallow_structure(\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\", line 1414, in _tf_data_assert_shallow_structure\n    raise TypeError(\n\nTypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: 'list'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 206, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was ((tf.float32, tf.float32), tf.float32), but the yielded element was ([array([[9.5120e+03, 9.2950e+03, 1.0000e+00, ..., 0.0000e+00, 0.0000e+00,\n        0.0000e+00],\n       [1.1456e+04, 1.5688e+04, 8.0160e+03, ..., 0.0000e+00, 0.0000e+00,\n        0.0000e+00],\n       [1.5506e+04, 1.8171e+04, 6.2740e+03, ..., 0.0000e+00, 0.0000e+00,\n        0.0000e+00],\n       ...,\n       [1.9070e+03, 1.8172e+04, 1.5506e+04, ..., 0.0000e+00, 0.0000e+00,\n        0.0000e+00],\n       [9.3730e+03, 9.1500e+03, 2.1803e+04, ..., 0.0000e+00, 0.0000e+00,\n        0.0000e+00],\n       [1.3134e+04, 9.1500e+03, 2.2358e+04, ..., 0.0000e+00, 0.0000e+00,\n        0.0000e+00]], dtype=float32), array([[  1., 270., 236., ...,   0.,   0.,   0.],\n       [  1., 270., 236., ...,   0.,   0.,   0.],\n       [  1., 270., 236., ...,   0.,   0.,   0.],\n       ...,\n       [  1., 270., 236., ...,   0.,   0.,   0.],\n       [  1., 270., 236., ...,   0.,   0.,   0.],\n       [  1., 270., 236., ...,   0.,   0.,   0.]], dtype=float32)], array([[[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       ...,\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)).\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_5535]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-5c09cd0416ea>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = nmt_model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     tf.data.Dataset.from_generator(\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         output_signature=(\n\u001b[1;32m      5\u001b[0m             (tf.TensorSpec(shape=(None, max_eng_seq_len), dtype=tf.float32),  \n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was ((tf.float32, tf.float32), tf.float32), but the yielded element was ([array([[9.5120e+03, 9.2950e+03, 1.0000e+00, ..., 0.0000e+00, 0.0000e+00,\n        0.0000e+00],\n       [1.1456e+04, 1.5688e+04, 8.0160e+03, ..., 0.0000e+00, 0.0000e+00,\n        0.0000e+00],\n       [1.5506e+04, 1.8171e+04, 6.2740e+03, ..., 0.0000e+00, 0.0000e+00,\n        0.0000e+00],\n       ...,\n       [1.9070e+03, 1.8172e+04, 1.5506e+04, ..., 0.0000e+00, 0.0000e+00,\n        0.0000e+00],\n       [9.3730e+03, 9.1500e+03, 2.1803e+04, ..., 0.0000e+00, 0.0000e+00,\n        0.0000e+00],\n       [1.3134e+04, 9.1500e+03, 2.2358e+04, ..., 0.0000e+00, 0.0000e+00,\n        0.0000e+00]], dtype=float32), array([[  1., 270., 236., ...,   0.,   0.,   0.],\n       [  1., 270., 236., ...,   0.,   0.,   0.],\n       [  1., 270., 236., ...,   0.,   0.,   0.],\n       ...,\n       [  1., 270., 236., ...,   0.,   0.,   0.],\n       [  1., 270., 236., ...,   0.,   0.,   0.],\n       [  1., 270., 236., ...,   0.,   0.,   0.]], dtype=float32)], array([[[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       ...,\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)).\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 204, in generator_py_func\n    flattened_values = nest.flatten_up_to(output_types, values)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/util/nest.py\", line 237, in flatten_up_to\n    return nest_util.flatten_up_to(\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\", line 1541, in flatten_up_to\n    return _tf_data_flatten_up_to(shallow_tree, input_tree)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\", line 1570, in _tf_data_flatten_up_to\n    _tf_data_assert_shallow_structure(shallow_tree, input_tree)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\", line 1444, in _tf_data_assert_shallow_structure\n    _tf_data_assert_shallow_structure(\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\", line 1414, in _tf_data_assert_shallow_structure\n    raise TypeError(\n\nTypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: 'list'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 206, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was ((tf.float32, tf.float32), tf.float32), but the yielded element was ([array([[9.5120e+03, 9.2950e+03, 1.0000e+00, ..., 0.0000e+00, 0.0000e+00,\n        0.0000e+00],\n       [1.1456e+04, 1.5688e+04, 8.0160e+03, ..., 0.0000e+00, 0.0000e+00,\n        0.0000e+00],\n       [1.5506e+04, 1.8171e+04, 6.2740e+03, ..., 0.0000e+00, 0.0000e+00,\n        0.0000e+00],\n       ...,\n       [1.9070e+03, 1.8172e+04, 1.5506e+04, ..., 0.0000e+00, 0.0000e+00,\n        0.0000e+00],\n       [9.3730e+03, 9.1500e+03, 2.1803e+04, ..., 0.0000e+00, 0.0000e+00,\n        0.0000e+00],\n       [1.3134e+04, 9.1500e+03, 2.2358e+04, ..., 0.0000e+00, 0.0000e+00,\n        0.0000e+00]], dtype=float32), array([[  1., 270., 236., ...,   0.,   0.,   0.],\n       [  1., 270., 236., ...,   0.,   0.,   0.],\n       [  1., 270., 236., ...,   0.,   0.,   0.],\n       ...,\n       [  1., 270., 236., ...,   0.,   0.,   0.],\n       [  1., 270., 236., ...,   0.,   0.,   0.],\n       [  1., 270., 236., ...,   0.,   0.,   0.]], dtype=float32)], array([[[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       ...,\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)).\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_5535]"
          ]
        }
      ]
    }
  ]
}